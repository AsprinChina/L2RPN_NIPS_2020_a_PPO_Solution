"""
In this file, a neural network is developed to fit the dataset generated by Tutor.
Feature is the observation of environment, 1221 dimensions.
Label is the action chosen by Tutor, 1 dimension, and 208 dimension after one-hot.

author: chen binbin
mail: cbb@cbb1996.com
"""
import sys
import time
import numpy as np
import tensorflow as tf


def data_process(npy_files):
    # Combine all training data
    data = None
    for file in npy_files:
        data = np.load(file) if data is None else np.concatenate((data, np.load(file)), axis=0)
    data = np.unique(data, axis=0)
    np.random.shuffle(data)

    # Assign label & features
    chosen = [0] + list(range(2, 7)) + list(range(7, 73)) + list(range(73, 184)) + list(range(184, 656))
    #       label      timestamp         generator-PQV            load-PQV               line-PQUI
    chosen += list(range(656, 715)) + list(range(715, 774)) + list(range(774, 833)) + list(range(833, 1010))
    #               line-rho               line switch         line-overload steps          bus switch
    chosen += list(range(1010, 1069)) + list(range(1069, 1105)) + list(range(1105, 1164)) + list(range(1164, 1223))
    #          line-cool down steps   substation-cool down steps     next maintenance         maintenance duration
    data = data[:, chosen]

    # Dataset partition
    num_sampling = data.shape[0]
    train_size = num_sampling * 8 // 10
    # validate_size = num_sampling // 10
    test_size = num_sampling // 10
    # s for state, feature; a for action, label.
    s_train, a_train = data[:train_size, 1:], data[:train_size, :1].astype(np.int32)
    s_validate, a_validate = data[train_size:-test_size, 1:], data[train_size:-test_size, :1].astype(np.int32)
    s_test, a_test = data[-test_size:, 1:], data[-test_size:, :1].astype(np.int32)

    return s_train, a_train, s_validate, a_validate, s_test, a_test


class Junior(object):
    def __init__(self):
        self.n_cell = 1000
        self.actions = 208
        self.lr = 5e-4
        self.activation = 'relu'
        self.lf = tf.keras.losses.SparseCategoricalCrossentropy()
        self.initializer = tf.keras.initializers.Orthogonal()
        self.model = self._build_model()

    def _build_model(self):
        model = tf.keras.models.Sequential([
            tf.keras.layers.Dense(self.n_cell, activation=self.activation, kernel_initializer=self.initializer),
            tf.keras.layers.Dense(self.n_cell, activation=self.activation, kernel_initializer=self.initializer),
            tf.keras.layers.Dense(self.n_cell, activation=self.activation, kernel_initializer=self.initializer),
            tf.keras.layers.Dropout(0.25),
            tf.keras.layers.Dense(self.n_cell, activation=self.activation, kernel_initializer=self.initializer),
            tf.keras.layers.Dropout(0.25),
            tf.keras.layers.Dense(self.actions, activation='softmax')
        ])
        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.lr),
                      loss=self.lf,
                      metrics=['accuracy'])
        return model

    def train(self, log_dir, ckpt_dir, x_train, y_train, x_validate, y_validate, epochs=100):
        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)
        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_dir,
                                                         save_weights_only=True,
                                                         period=10,
                                                         verbose=1)
        self.model.fit(x=x_train,
                       y=y_train,
                       epochs=epochs,
                       validation_data=(x_validate, y_validate),
                       callbacks=[tensorboard_callback, cp_callback])

    def test(self, x, y, save_path=None):
        if save_path is not None:
            self.model.load_weights(save_path)

        a_pred = self.model.predict(x, verbose=1)
        top_n = []
        for i in range(a_pred.shape[0]):
            top_n.append(a_pred[i, :].argsort()[-20:])
        for n in range(1, 21):
            correct = 0
            for i in range(a_pred.shape[0]):
                if y[i, 0] in top_n[i][-n:]:
                    correct += 1
            print('accuracy of top-%d is %.2f%%' % (n, correct / a_pred.shape[0] * 100))


if __name__ == '__main__':
    # Initialize
    junior = Junior()
    npy_files = ['./TrainingData/records_11-13-11-18.npy']  # for demo only, use your own dataset
    np.random.seed(10)
    s_train, a_train, s_validate, a_validate, s_test, a_test = data_process(npy_files)

    # Task perform
    # task = sys.argv[1]
    task = 'Convert'
    if task == 'Train':
        # Task-Train
        log_dir = 'tfboard/' + time.strftime("%m-%d-%H-%M", time.localtime())
        ckpt_dir = 'ckpt/cp-{epoch:04d}.ckpt'
        junior.train(log_dir, ckpt_dir, s_train, a_train, s_validate, a_validate, 100)
    elif task == 'Test':
        # Task-Test
        save_path = './ckpt/cp-0050.ckpt'  # for demo only, use your own data
        junior.test(s_test, a_test, save_path)
    elif task == 'Convert':
        # Convert saving format
        save_path = './ckpt/cp-0050.ckpt'  # for demo only, use your own data
        junior.model.load_weights(save_path)
        junior.model.predict(np.zeros((1, s_train.shape[-1])))
        junior.model.save('../SeniorStudent/JuniorModel')
    else:
        print('Supported tasks: Train, Test, Convert.')
